<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Khanh Nguyen</title>
    <link rel="stylesheet" href="../../css/main.css">
</head>
<body>
    <div class="include" url="../template/navbar.html"></div>
    <div class="content">
        <div id="highlight" name="blog" ></div>
        <h1>Textbook Recommendation</h1>
        All of them <a href="book.bib">here</a>

        <ul>
            <li>
                <b>Jorge Nocedal and Stephen Wright. Numerical optimization. Springer Science & Business Media,
                    2006.</b>
                <br>
                <i>
                    a good book for numerical optimization, have not read all of it.
                    ../10
                </i>
            </li>
            <li>
                <b>Thomas H Cormen, Charles E Leiserson, Ronald L Rivest, and Clifford Stein. Introduction to
                    algorithms. MIT press, 2009.</b>
                <br>
                <i>
                    The reference book for CZ4016 (Advanced Topics in Algorithms) - Really good introduction book.
                    9/10
                </i>
            </li>
            <li>
                <b>Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. Deep learning, volume 1. MIT
                    press Cambridge, 2016.</b>
                <br>
                <i>
                    How to start with deep learning, the book everyone recommend. Pretty boring btw.
                    5/10
                </i>
            </li>
            <li>
                <b>Kevin P Murphy. Machine learning: a probabilistic perspective. MIT press, 2012.</b>
                <br>
                <i>
                    The real book for how to start with deep learning. Have not read much of it, but it is
                    definitely a really good reference book.
                    9/10
                </i>
            <li>
                <b>Jerome Friedman, Trevor Hastie, and Robert Tibshirani. The elements of statistical learning,
                    volume 1. Springer series in statistics New York, 2001.</b>
                <br>
                <i>
                    Everyone's choice for machine learning. Much more easier than Murphy's book.
                    6/10
                </i>
            </li>
            <li>
                <b>Ian Stewart. Concepts of modern mathematics. Courier Corporation, 1995.</b>
                <br>
                <i>
                    "Khoa hoc thuong thuc" kind of book. Suitable for everyone want to understand what people are
                    doing in "modern maths",
                    8/10
                </i>
            </li>
            <li>
                <b>Michael Sipser. Introduction to the theory of computation. ACM Sigact News, 27(1):27--29,
                    1996.</b>
                <br>
                <i>
                    All Computer Science Undergraduates should read this. Perfect choice for explaining how computer works.
                    10/10
                </i>
            </li>
            <li>
                <b>Stephen Boyd, Stephen P Boyd, and Lieven Vandenberghe. Convex optimization. Cambridge university
                    press, 2004.</b>
                <br>
                <i>
                    Together with Boyd's undergraduate course: Convex Optimization CS334A EE364A CME364A. The course
                    is very detailed explanation to convex optimization.
                    <br>
                    A must-read book for CS students.
                    9/10
                </i>
            </li>
            <li>
                <b>Sheldon Axler. Linear algebra done right. Springer, 2015.</b>
                <br>
                <i>
                    Currently studying this book for GRE.
                    <br>
                    Honestly, Linear Algebra is a hard subject at the beginning,
                    especially for a Physics background like me where all concepts started with their abstract
                    representations.
                    <br>
                    This should be taught together with
                    a basic Linear Algebra book focusing on vectors, matrices applications
                    and
                    an Abstract Algebra book focusing on abstract representation of those objects.
                    Keep in mind (analogy) that a linear map is corresponding to a matrix, or a vector,
                    dimension is just physics dimension, orthogonal complement is just the subspace consists of the
                    rest of basis.
                    Even though, it is very vague. It is good way to remember the concepts.
                    10/10
                </i>
            </li>
            <li>
                <b>Stephen Abbott. Understanding analysis. Springer Science & Business Media, 2012.</b>
                <br>
                <i>
                    Currently studying this book for GRE.
                    A decent textbook. Proofs are rigorous but many of them are left for exercise.
                    (Personally, I think the important thing is the trick, other than that, all proofs are just a
                    result of massively search for the correct use of theorems and axioms).
                    The ending is like a dopamine pill, he introduced a construction of real set from rational set,
                    beautifully.
                    7/10.
                </i>
            </li>

        </ul>
    </div>
    <div class="include" url="../../footer.html"></div>
    <script src="../../js/post_script.js"></script>
</body>
</html>
