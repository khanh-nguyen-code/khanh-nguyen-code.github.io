<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Khanh Nguyen</title>
    <link rel="stylesheet" href="css/main.css">
</head>
<body>
    <div class="include" url="navbar.html"></div>
    <div class="content">
        <div id="highlight" name="blog" ></div>

        <h1>My unordered thoughts</h1>
        <b>Unanswered questions</b>:
        <ul>
            <li><i>Is P = NP?</i></li>
            <li><i>Does evolutionary computation have any advance beyond other randomized algorithm implementation?</i></li>
            <li><i>Duality Gap is interesting. What makes hard problems hard?</i></li>
            <li><i>
                Can we classify NP problems into distinct hardness sets such that each of the sets has its own algorithm to solve?
                <br>
                e.g: P problems, crypto problems, P-complete problems, etc.
            </i></li>
            <li><i>
                1-norm has a better capability to extract the sparse solutions.
                <br>
                Is there any complexity class corresponding to 1-norm? (of course &lt;1-norm is not convex)
                <br>
                How about atomic norm?
            </i></li>
            <li><i>
                I've read about how adding number of neurons equals to the number of outputs makes all the bad local optimal vanish.
                <br>
                So cool! gonna read about this seriously
            </i></li>
            <li><i>
                another research is about the connection between implicit regularization (initialize weights to be near zero) and rank minimization.
                <br>
                another cool topic to read
            </i></li>
            <li><i>
                my next textbook to self teach is "Abstract Algebra - Dummit"
            </i></li>
        </ul>
        <br>
        <b>Answered Questions</b>:
        <br>
        <ul>
            <li>It seems like I prefer reals than integers.</li>
            <li>Thank CS course for teaching me what logic looks like</li>
        </ul>

        <h1>Textbook Recommendation</h1>
        All of them <a href="/blog/book.bib">here</a>

        <ul>
            <li>
                <b>Jorge Nocedal and Stephen Wright. Numerical optimization. Springer Science & Business Media,
                    2006.</b>
                <br>
                <i>
                    a good book for numerical optimization, have not read all of it.
                    ../10
                </i>
            </li>
            <li>
                <b>Thomas H Cormen, Charles E Leiserson, Ronald L Rivest, and Clifford Stein. Introduction to
                    algorithms. MIT press, 2009.</b>
                <br>
                <i>
                    The reference book for CZ4016 (Advanced Topics in Algorithms) - Really good introduction book.
                    9/10
                </i>
            </li>
            <li>
                <b>Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. Deep learning, volume 1. MIT
                    press Cambridge, 2016.</b>
                <br>
                <i>
                    How to start with deep learning, the book everyone recommend. Pretty boring btw.
                    5/10
                </i>
            </li>
            <li>
                <b>Kevin P Murphy. Machine learning: a probabilistic perspective. MIT press, 2012.</b>
                <br>
                <i>
                    The real book for how to start with deep learning. Have not read much of it, but it is
                    definitely a really good reference book.
                    9/10
                </i>
            <li>
                <b>Jerome Friedman, Trevor Hastie, and Robert Tibshirani. The elements of statistical learning,
                    volume 1. Springer series in statistics New York, 2001.</b>
                <br>
                <i>
                    Everyone's choice for machine learning. Much more easier than Murphy's book.
                    6/10
                </i>
            </li>
            <li>
                <b>Ian Stewart. Concepts of modern mathematics. Courier Corporation, 1995.</b>
                <br>
                <i>
                    "Khoa hoc thuong thuc" kind of book. Suitable for everyone want to understand what people are
                    doing in "modern maths",
                    8/10
                </i>
            </li>
            <li>
                <b>Michael Sipser. Introduction to the theory of computation. ACM Sigact News, 27(1):27--29,
                    1996.</b>
                <br>
                <i>
                    All Computer Science Undergraduates should read this. Perfect choice for explaining how computer works.
                    10/10
                </i>
            </li>
            <li>
                <b>Stephen Boyd, Stephen P Boyd, and Lieven Vandenberghe. Convex optimization. Cambridge university
                    press, 2004.</b>
                <br>
                <i>
                    Together with Boyd's undergraduate course: Convex Optimization CS334A EE364A CME364A. The course
                    is very detailed explanation to convex optimization.
                    <br>
                    A must-read book for CS students.
                    9/10
                </i>
            </li>
            <li>
                <b>Sheldon Axler. Linear algebra done right. Springer, 2015.</b>
                <br>
                <i>
                    Currently studying this book for GRE.
                    <br>
                    Honestly, Linear Algebra is a hard subject at the beginning,
                    especially for a Physics background like me where all concepts started with their abstract
                    representations.
                    <br>
                    This should be taught together with
                    a basic Linear Algebra book focusing on vectors, matrices applications
                    and
                    an Abstract Algebra book focusing on abstract representation of those objects.
                    Keep in mind (analogy) that a linear map is corresponding to a matrix, or a vector,
                    dimension is just physics dimension, orthogonal complement is just the subspace consists of the
                    rest of basis.
                    Even though, it is very vague. It is good way to remember the concepts.
                    10/10
                </i>
            </li>
            <li>
                <b>Stephen Abbott. Understanding analysis. Springer Science & Business Media, 2012.</b>
                <br>
                <i>
                    Currently studying this book for GRE.
                    A decent textbook. Proofs are rigorous but many of them are left for exercise.
                    (Personally, I think the important thing is the trick, other than that, all proofs are just a
                    result of massively search for the correct use of theorems and axioms).
                    The ending is like a dopamine pill, he introduced a construction of real set from rational set,
                    beautifully.
                    7/10.
                </i>
            </li>

        </ul>

        <h1>Others</h1>

        <ul>
            <li>
                Pi digit extraction: <a href="./blog/pi_digit_extraction/pi_digit_extraction.html">here</a>
            </li>
            <li>
                A bouncing ball: <a href="blog/bouncing_ball/bouncing_ball.html">here</a>
            </li>
            <li>
                Approximate real function using power series: <a href="https://github.com/khanhhhh/power_series_approximation">here</a>
            </li>

            <li>
                Calculate arbitrary digit of Pi: <a href="https://github.com/khanhhhh/pi_digit_extraction">here</a>
            </li>
            <li>
                Courses: <a href="./blog/course/course.html">here</a>
            </li>
            <li>
                Conflict based search: <a href="./blog/conflict-based-search/conflict_based_search.html">here</a>
                originated from <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/viewFile/5062/5239">here</a>
            </li>
            <li>
                My sudoku game: <a href="https://github.com/khanhhhh/sudoku">here</a>
            </li>
            <li>
                An unique solution: <a href="./blog/unique_solution/unique_solution.html">here</a>
            </li>
            <li>
                An approximation pattern: <a href="./blog/approximation_pattern/approximation_pattern.html">
                here</a>
                originated from <a href="http://www.ifaamas.org/Proceedings/aamas2019/pdfs/p1479.pdf">here</a>
            </li>
            <li>
                TSP using Simulated Annealing: <a href="./blog/simulated_annealing/simulated_annealing.html">here</a>
            </li>
            <li>
                My FYP Report: <a href="https://dr.ntu.edu.sg/handle/10356/144629">here</a>
            </li>
            <li>
                My FYP Code: <a href="https://github.com/khanhhhh/ddcrp-graph">here</a>
            </li>
            <li>
                Solving sparsest solution for underdetermined linear system for compressed sensing: <a
                    href="https://github.com/khanhhhh/sparse-uls">here</a>
            </li>
            <li>
                Simple game based on multi agent path finding: <a
                    href="https://github.com/khanhhhh/mapf">here</a>
            </li>
            <li>
                Solving some simple combinatorial problem with MIP solver: <a
                    href="https://github.com/khanhhhh/mip-solver">here</a>
            </li>
            <li>
                Copy your text then it will speak to mic for you <a
                    href="https://github.com/khanhhhh/text2mic">here</a>
            </li>
            <li>
                LADIES: <a href="https://github.com/khanhhhh/ladies">here</a>
            </li>
            <li>
                Simple stack machine: <a href="https://github.com/khanhhhh/vm">here</a>
            </li>
            <li>
                SID: <a href="https://github.com/khanhhhh/survey-inspired-decimation-sat">here</a>
            </li>
        </ul>

    </div>
    <div class="include" url="footer.html"></div>
    <script src="js/post_script.js"></script>
</body>
</html>
